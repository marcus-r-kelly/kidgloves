import numpy as np
import sys
import pandas as pd
import kidgloves as kg
from functools import reduce,partial
import yaml
import os
opj=os.path.join

import argparse
parser=argparse.ArgumentParser()
parser.add_argument(
        '--cohort',
        action='store',
        help='TCGA cohort code',
        required=True)
parser.add_argument(
        '--cohort_signature_table',
        action='store',
        help='name of file containing cohort signature table (generated by dump_signatures.py)',
        required=True)
parser.add_argument(
        '--output_path',
        action='store',
        help='output folder',
        required=True)

parser.add_argument(
        '--config_file',
        action='store',
        default=opj(os.getenv('HOME'),'.config','kgconfig.yaml'),
        help='location of desired kgconfig file')

parser.add_argument(
        '--max_nest_system_size',
        action='store',
        default=50,
        help='Largest system size to allow when pulling hierarchy data')

ns=parser.parse_args()

cohort_signature_table=ns.cohort_signature_table
outpath=ns.output_path
cohort=ns.cohort
cu=cohort.upper()
cl=cohort.lower()

if not os.path.exists(outpath) : 
    os.mkdir(outpath)

with open(ns.config_file,'r') as y :
    kgc=yaml.safe_load(y)

#TODO check that all these matter

assert os.path.isdir(kgc.get('cbioportal_folder_prefix'))
assert os.path.isdir(kgc.get('signature_folder_prefix'))
assert os.path.exists(kgc.get('nest_hierarchy_path'))

#casedatapath=opj(kgc['signature_folder_prefix'],'casedata')
#aliquotpath=opj(casedatapath,'aliquot.tsv')
thiscohortpath=opj(kgc['signature_folder_prefix'],'cohort_'+cl)

cbioportal_path=opj(kgc['cbioportal_folder_prefix'],cl+'_tcga_pan_can_atlas_2018')


NEST_HIERARCHY_PATH=kgc['nest_hierarchy_path']
#TODO: this needs to get  moved into its own script that saves the signature/arm frame
# then, that frame needs to be read and pointed to in this script
#~~~~~~~~Read in and format omics signatures~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print('Loading signatures...',end='')
if cu == 'COADREAD' : 
    thisnestcancer='COAD'
else: 
    thisnestcancer=cu

msigframe=pd.read_csv(cohort_signature_table,index_col=0)
print('Done.')



#~~~~~~~~Read in the relevant parts of nest~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print('Reading in hierarchy...',end='')
nestdf=kg.load_nest(kgc['nest_hierarchy_path'])
#nestdf=nestdf[ nestdf['Size'].le(50) & nestdf['No. significantly mutated cancer types'].ge(1) ]
nestdf=nestdf[nestdf['Size'].le(int(ns.max_nest_system_size)) & 
    (nestdf['Significantly mutated cancer types'].str.contains(thisnestcancer)  | nestdf['No. significantly mutated cancer types'].ge(2)) ]

   #nest_cancer_types={ ct for ctl in nestdf['Significantly mutated cancer types'].values for ct in ctl.split(' ')} -{'',} 
   #if cl == "coadread"  : 
   #    nestdf=nestdf[ nestdf['Size'].le(50) & nestdf['Significantly mutated cancer types'].str.contains("COAD") ]
   #elif cl not in nest_cancer_types : 
   #    nestdf=nestdf[ nestdf['Size'].le(50) ]
   #else : 
   #    nestdf=nestdf[ nestdf['Size'].le(50) & nestdf['Significantly mutated cancer types'].str.contains(cu) ]

nest=kg.extract_nest_systems(nestdf)
nest_genes={ g for s in nest.values() for g in s }
nest_genes=nest_genes - {'',}
print('Done.')

#~~~~~~~~Read in and transform cancer data~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print('Reading in lesions...',end='')
CBIOPORTAL_PATH=opj(kgc['cbioportal_folder_prefix'],cl+'_tcga_pan_can_atlas_2018')
preomics=kg.autoload_events(CBIOPORTAL_PATH,gene_set=list(nest_genes))
preomics.index=[ '-'.join(x.split('-')[:-1]) for x in preomics.index]
omics=preomics.reindex(msigframe.index).fillna(0)
omics=omics[ omics.columns[omics.sum().ne(0)]]
print('Done.')

#~~~~~~~~... to create the training data... ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
print('Training models...',end='')
sys.stdout.flush()
from sklearn.preprocessing import MaxAbsScaler
ft=pd.DataFrame(
    data=MaxAbsScaler().fit_transform(msigframe),
    index=msigframe.index,
    columns=msigframe.columns)
    

#~~~~~~~~... and use it to train the logit regressions~~~~~~~~~~~~~~~~~~~~~~~~~~
lt=kg.LogitTransformer(training_data=omics)
#~~~~~~~~VVV this defines the coefficients for each patient~~~~~~~~~~~~~~~~~~~~~
# the object can generate new patients

logit_data=lt.fit(ft)
logit_data.to_csv(opj(outpath,'logit_data.csv'))

import pickle
lt.save(opj(outpath,'logittransformer.pickle'))

print('Done.')

#~~~~~~~~Finally, we need to grab the relevant nest systems~~~~~~~~~~~~~~~~~~~~~
print('Summarizing...',end='')
nestmaskdict=kg.mask_nest_systems(nest,logit_data)
with open(opj(outpath,'nestmaskdict.pickle'),'wb') as f : 
    pickle.dump(nestmaskdict,f)


protorst=pd.DataFrame(logit_data)
protorst=protorst.assign(symbol=protorst.gene.apply(kg._e2s.get))
protorst=protorst.assign(symbol_lesion=protorst.symbol+'_'+protorst.lesion_overclass)
protorst=protorst.set_index('symbol_lesion')

protorst_metacols=kg._metacols+['symbol']

colgroups={ 'mutation_signatures' : { c for c in protorst.columns if any([ c.startswith(pref) for pref in ('SBS','ID','DBS') ]) },
            'cna_signatures' : { c for c in protorst.columns if c.startswith('CN') },
            'cna_arm_pcs' : { c for c in protorst.columns if c.startswith('arm_pc') }}

rst=pd.DataFrame(protorst[protorst_metacols])
rst=rst.assign(**{ cgk : [ ( r[list(cg)] != 0 ).sum() for x,r in protorst.iterrows() ]
                             for cgk,cg in colgroups.items() })
rst=rst.assign(**{ 'n_explanations' : [ rst.loc[x,list(colgroups.keys())].sum() for x in rst.index ] })
rst.to_csv(opj(outpath,'explanation_summaries.csv'))
print('Done.')



            




